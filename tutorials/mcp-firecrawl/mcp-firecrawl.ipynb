{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5dad247",
   "metadata": {},
   "source": [
    "# Groq + Firecrawl MCP: AI-Powered Web Scraping & Data Extraction\n",
    "This notebook demonstrates how to empower Groq inference with enterprise-grade web scraping capabilities using Firecrawl's Model Context Protocol (MCP) server for intelligent data extraction, structured parsing, and deep web research.\n",
    "\n",
    "We will achieve this through three simple steps:\n",
    "1. Set up **Groq MCP client** for fast inference.\n",
    "2. Set up **Firecrawl MCP server** for enterprise web scraping.\n",
    "3. Seamlessly **connect the client to the server** through the Responses API.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1c6b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install dependencies\n",
    "%pip install openai python-dotenv ipython\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205d57e0",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "Follow these steps to set up:\n",
    "1. **Sign up** for Groq at [console.groq.com](https://console.groq.com/keys) to get your free API key.\n",
    "2. **Sign up** for Firecrawl at [firecrawl.dev/app/api-keys](https://firecrawl.dev/app/api-keys) to get your API key.\n",
    "3. **Copy your API keys** from your Groq and Firecrawl account dashboards.\n",
    "4. **Paste your API keys** into the cell below and run the cell.\n",
    "\n",
    "*Note: do **not** run the cell below if your keys are already configured in an .env file in this directory*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8cd2b381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To export your API keys into a .env file, run the following cell (replace with your actual keys):\n",
    "!echo \"GROQ_API_KEY=<your-groq-api-key>\" >> .env\n",
    "!echo \"FIRECRAWL_API_KEY=<your-firecrawl-api-key>\" >> .env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3da8da46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groq API key configured successfully!\n",
      "Firecrawl API key configured successfully!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from openai import OpenAI\n",
    "from openai.types import responses as openai_responses\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "FIRECRAWL_API_KEY = os.getenv(\"FIRECRAWL_API_KEY\")\n",
    "\n",
    "if not GROQ_API_KEY:\n",
    "    print(\"Please set your Groq API key\")\n",
    "else:\n",
    "    print(\"Groq API key configured successfully!\")\n",
    "if not FIRECRAWL_API_KEY:\n",
    "    print(\"Please set your Firecrawl API key\")\n",
    "else:\n",
    "    print(\"Firecrawl API key configured successfully!\")\n",
    "    \n",
    "MODEL = \"openai/gpt-oss-120b\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a74723f",
   "metadata": {},
   "source": [
    "## Step 1: Set up the Groq client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0315ba6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "client = OpenAI(base_url=\"https://api.groq.com/api/openai/v1\", api_key=GROQ_API_KEY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a8b94b",
   "metadata": {},
   "source": [
    "## Step 2: Set up Firecrawl's remote MCP server\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "42b3e4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up Firecrawl MCP server\n",
    "tools = [\n",
    "    openai_responses.tool_param.Mcp(\n",
    "        server_label=\"firecrawl\",\n",
    "        server_url=f\"https://mcp.firecrawl.dev/{FIRECRAWL_API_KEY}/v2/sse\",\n",
    "        type=\"mcp\",\n",
    "        require_approval=\"never\",\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629b672a",
   "metadata": {},
   "source": [
    "## Step 3: Connect Groq to the Firecrawl MCP through Groq's Responses API\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b14893b",
   "metadata": {},
   "source": [
    "This will be our **main** function we use to call the Groq API. It's been formatted to give us slightly more information into how MCPs work and their efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e9569e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_groq_with_tools(client, tools, query):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    response = client.responses.create(\n",
    "        model=MODEL,\n",
    "        input=query,\n",
    "        tools=tools,\n",
    "        stream=False,\n",
    "        temperature=0.1,\n",
    "        top_p=0.4,\n",
    "    )\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "\n",
    "    content = (\n",
    "        response.output_text if hasattr(response, \"output_text\") else str(response)\n",
    "    )\n",
    "\n",
    "    executed_tools = []\n",
    "\n",
    "    if hasattr(response, \"output\") and response.output:\n",
    "        for output_item in response.output:\n",
    "            if hasattr(output_item, \"type\") and output_item.type == \"mcp_call\":\n",
    "                executed_tools.append(\n",
    "                    {\n",
    "                        \"type\": \"mcp\",\n",
    "                        \"arguments\": getattr(output_item, \"arguments\", \"{}\"),\n",
    "                        \"output\": getattr(output_item, \"output\", \"\"),\n",
    "                        \"name\": getattr(output_item, \"name\", \"\"),\n",
    "                        \"server_label\": getattr(output_item, \"server_label\", \"\"),\n",
    "                    }\n",
    "                )\n",
    "    return {\n",
    "        \"content\": content,\n",
    "        \"total_time\": total_time,\n",
    "        \"mcp_calls_performed\": executed_tools,\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8208da",
   "metadata": {},
   "source": [
    "Let's implement a helper function to display MCP tool calls and their results. This will provide transparency into which tools were called, their arguments, and outputs. \n",
    "\n",
    "(This is generally useful when debugging if you need to view raw MCP outputs, it's not vital for functionality)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953dd63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_mcp_calls(mcp_calls):\n",
    "    executed_tools = mcp_calls[\"mcp_calls_performed\"]\n",
    "    if executed_tools:\n",
    "        print(f\"\\nFIRECRAWL MCP CALLS: Found {len(executed_tools)} tool call(s):\")\n",
    "        print(\"-\" * 50)\n",
    "        for i, tool in enumerate(executed_tools, 1):\n",
    "            print(f\"\\nTool Call #{i}\")\n",
    "            print(f\"   Type: {tool['type']}\")\n",
    "            print(f\"   Tool Name: {tool['name']}\")\n",
    "            print(f\"   Server: {tool['server_label']}\")\n",
    "            try:\n",
    "                if tool[\"arguments\"]:\n",
    "                    args = (\n",
    "                        json.loads(tool[\"arguments\"])\n",
    "                        if isinstance(tool[\"arguments\"], str)\n",
    "                        else tool[\"arguments\"]\n",
    "                    )\n",
    "                    print(f\"   Arguments: {args}\")\n",
    "\n",
    "                if tool[\"output\"]:\n",
    "                    output_data = (\n",
    "                        json.loads(tool[\"output\"])\n",
    "                        if isinstance(tool[\"output\"], str)\n",
    "                        else tool[\"output\"]\n",
    "                    )\n",
    "                    if isinstance(output_data, dict):\n",
    "                        if \"url\" in output_data:\n",
    "                            print(f\"   URL Scraped: {output_data['url']}\")\n",
    "                        if \"success\" in output_data:\n",
    "                            print(f\"   Success: {output_data['success']}\")\n",
    "                        if \"markdown\" in output_data:\n",
    "                            content_preview = output_data[\"markdown\"][:200] + \"...\" if len(output_data[\"markdown\"]) > 200 else output_data[\"markdown\"]\n",
    "                            print(f\"   Content Preview: {content_preview}\")\n",
    "                    else:\n",
    "                        print(f\"   Output: {str(output_data)[:200]}...\")\n",
    "            except Exception as e:\n",
    "                print(f\"   Could not parse tool data: {e}\")\n",
    "    print(f\"   Total time: {mcp_calls['total_time']:.2f} seconds\")\n",
    "    print(f\"   Firecrawl MCP calls: {len(mcp_calls['mcp_calls_performed'])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b62ff3c",
   "metadata": {},
   "source": [
    "# Examples\n",
    "\n",
    "**Note:** Some queries may consume more tokens than others depending on the amount of tool calls the model makes. Please be aware of various rate limits that are tied to your API keys if you happen to run into any rate limit errors. \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e977c5",
   "metadata": {},
   "source": [
    "## Demo 1: Website Analysis & Content Scraping\n",
    "\n",
    "Let's build a web scraper that analyzes Anthropic's website to extract comprehensive company information, products, and recent announcements using Firecrawl's intelligent scraping capabilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "47d78212",
   "metadata": {},
   "outputs": [
    {
     "ename": "APIStatusError",
     "evalue": "Error code: 424 - {'error': {'message': \"Error retrieving tool list from MCP server: 'firecrawl' Http status code: 404 (Not Found)\", 'type': 'external_connector_error', 'param': 'tools', 'code': 'http_error'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAPIStatusError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[56]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIPython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Markdown\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m website_analysis = \u001b[43mcall_groq_with_tools\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mScrape and analyze the website https://anthropic.com. Provide a comprehensive overview of what the company does, their main products/services, key features, and any recent announcements.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[55]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mcall_groq_with_tools\u001b[39m\u001b[34m(client, tools, query)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_groq_with_tools\u001b[39m(client, tools, query):\n\u001b[32m      3\u001b[39m     start_time = time.time()\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresponses\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMODEL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m     total_time = time.time() - start_time\n\u001b[32m     16\u001b[39m     content = (\n\u001b[32m     17\u001b[39m         response.output_text \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(response, \u001b[33m\"\u001b[39m\u001b[33moutput_text\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(response)\n\u001b[32m     18\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/openai/resources/responses/responses.py:828\u001b[39m, in \u001b[36mResponses.create\u001b[39m\u001b[34m(self, background, conversation, include, input, instructions, max_output_tokens, max_tool_calls, metadata, model, parallel_tool_calls, previous_response_id, prompt, prompt_cache_key, reasoning, safety_identifier, service_tier, store, stream, stream_options, temperature, text, tool_choice, tools, top_logprobs, top_p, truncation, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    791\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    792\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    793\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m    826\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = not_given,\n\u001b[32m    827\u001b[39m ) -> Response | Stream[ResponseStreamEvent]:\n\u001b[32m--> \u001b[39m\u001b[32m828\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    829\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/responses\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    830\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    831\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    832\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbackground\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackground\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    833\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mconversation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mconversation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    834\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minclude\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    835\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    836\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minstructions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    837\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_output_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_output_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    838\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    839\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    840\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    841\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprevious_response_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprevious_response_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    844\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    845\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    846\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    847\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    848\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    849\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    850\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    851\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    852\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    853\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    854\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    855\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    856\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    857\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtruncation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    858\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    859\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    860\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresponse_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mResponseCreateParamsStreaming\u001b[49m\n\u001b[32m    861\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m    862\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mResponseCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    863\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    864\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    865\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    866\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    867\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    868\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    869\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mResponseStreamEvent\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    870\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/openai/_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/openai/_base_client.py:1047\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1044\u001b[39m             err.response.read()\n\u001b[32m   1046\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1047\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mAPIStatusError\u001b[39m: Error code: 424 - {'error': {'message': \"Error retrieving tool list from MCP server: 'firecrawl' Http status code: 404 (Not Found)\", 'type': 'external_connector_error', 'param': 'tools', 'code': 'http_error'}}"
     ]
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "website_analysis = call_groq_with_tools(\n",
    "    client,\n",
    "    tools,\n",
    "    \"Scrape and analyze the website https://anthropic.com. Provide a comprehensive overview of what the company does, their main products/services, key features, and any recent announcements.\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ca4b43",
   "metadata": {},
   "source": [
    "Let's display the agent's response in markdown format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a389aed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(website_analysis[\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff49e5f4",
   "metadata": {},
   "source": [
    "Let's examine the agent's intermediate steps, including how it calls different Firecrawl tools and configures tool arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0844f7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_mcp_calls(website_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caabea6d",
   "metadata": {},
   "source": [
    "## Demo 2: Structured Data Extraction\n",
    "\n",
    "Now we'll create a competitive analysis tool that extracts structured pricing data from multiple AI companies (OpenAI, Anthropic, Groq) and formats it into consistent JSON schemas for easy comparison.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9207c01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_extraction = call_groq_with_tools(\n",
    "    client,\n",
    "    tools,\n",
    "    \"\"\"Use the firecrawl_extract tool to extract structured pricing information from these AI company websites:\n",
    "    \n",
    "    URLs: https://openai.com, https://anthropic.com, https://groq.com\n",
    "    \n",
    "    Extract the following data for each company in JSON format:\n",
    "    {\n",
    "        \"company_name\": \"string\",\n",
    "        \"pricing_plans\": [\n",
    "            {\n",
    "                \"plan_name\": \"string\",\n",
    "                \"price\": \"string\",\n",
    "                \"features\": [\"string\"]\n",
    "            }\n",
    "        ],\n",
    "        \"contact_info\": \"string\",\n",
    "        \"main_product\": \"string\"\n",
    "    }\n",
    "    \n",
    "    Focus on finding current pricing information and structure it consistently across all companies.\"\"\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90bb9da",
   "metadata": {},
   "source": [
    "Let's display the structured extraction results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f4c362",
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(structured_extraction[\"content\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294eb59b",
   "metadata": {},
   "source": [
    "Let's examine the agent's intermediate steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b473c169",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_mcp_calls(structured_extraction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ac88c1",
   "metadata": {},
   "source": [
    "## Demo 3: Deep Research & Multi-hop Analysis\n",
    "\n",
    "Here we'll build an AI research agent that conducts comprehensive multi-hop research on AI inference trends, automatically discovering and analyzing multiple sources to create a detailed research report with proper citations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44071aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_research = call_groq_with_tools(\n",
    "    client,\n",
    "    tools,\n",
    "    \"\"\"Conduct comprehensive deep research on \"latest trends in AI model inference speed and performance\" using the firecrawl_deep_research tool.\n",
    "    \n",
    "    Research should include:\n",
    "    1. Recent developments in AI inference optimization (2024-2025)\n",
    "    2. Key companies and technologies leading this space\n",
    "    3. Performance benchmarks and comparison data\n",
    "    4. Future trends and implications\n",
    "    \n",
    "    Use deep research capabilities to find and analyze multiple authoritative sources. Provide a comprehensive report with proper citations.\"\"\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87a9c96",
   "metadata": {},
   "source": [
    "Let's display the deep research report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b372c1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(deep_research[\"content\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb207603",
   "metadata": {},
   "source": [
    "Let's examine the deep research process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d458def",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_mcp_calls(deep_research)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10de3e4",
   "metadata": {},
   "source": [
    "## Demo 4: Try it Yourself\n",
    "\n",
    "Now it's your turn! Create your own custom web intelligence agent by replacing the query below with your specific web scraping, data extraction, or research task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4feced77",
   "metadata": {},
   "outputs": [],
   "source": [
    "your_query = \"Your Query Here\"  # Change this!\n",
    "\n",
    "custom_response = call_groq_with_tools(client, tools, your_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85724a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(custom_response[\"content\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a88081",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_mcp_calls(custom_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd591d17",
   "metadata": {},
   "source": [
    "## Available Firecrawl MCP Tools\n",
    "\n",
    "Firecrawl MCP provides several powerful tools for web scraping, data extraction, and research:\n",
    "\n",
    "| Tool | Description |\n",
    "|------|-------------|\n",
    "| **`firecrawl_scrape`** | Scrape content from a single URL with advanced options and formatting |\n",
    "| **`firecrawl_batch_scrape`** | Scrape multiple URLs efficiently with built-in rate limiting and parallel processing |\n",
    "| **`firecrawl_check_batch_status`** | Check the status of a batch operation and retrieve results |\n",
    "| **`firecrawl_search`** | Search the web and optionally extract content from search results |\n",
    "| **`firecrawl_crawl`** | Start an asynchronous crawl with advanced options for depth and link following |\n",
    "| **`firecrawl_extract`** | Extract structured information from web pages using LLM capabilities and JSON schemas |\n",
    "| **`firecrawl_deep_research`** | Conduct comprehensive deep web research with intelligent crawling and LLM analysis |\n",
    "| **`firecrawl_generate_llmstxt`** | Generate standardized llms.txt files that define how LLMs should interact with a site |\n",
    "\n",
    "### Key Benefits\n",
    "\n",
    "1. **Enterprise-Grade Reliability**: Handles JavaScript, authentication, and dynamic content\n",
    "2. **AI-Powered Intelligence**: Understands content semantically, not just structurally  \n",
    "3. **Batch Processing**: Efficient parallel operations for production workloads\n",
    "4. **Speed**: Sub-10 second responses when combined with Groq's fast inference\n",
    "5. **Transparency**: Full visibility into tool calls and data sources\n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "You've just experienced fast AI-powered web intelligence that combines:\n",
    "- **Fast responses** (3-10 seconds) via Groq inference\n",
    "- **Enterprise web scraping** with Firecrawl's advanced capabilities  \n",
    "- **Structured data extraction** using AI-powered parsing\n",
    "- **Deep research** with multi-hop reasoning and source transparency\n",
    "\n",
    "This approach enables you to build applications that need both speed and reliability for web data collection and analysis tasks.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
